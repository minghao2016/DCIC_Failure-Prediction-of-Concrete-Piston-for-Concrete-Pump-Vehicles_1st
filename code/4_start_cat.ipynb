{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pinlan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import datetime\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from tqdm import *\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, RepeatedKFold,train_test_split,StratifiedKFold\n",
    "# from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
    "from sklearn.metrics import f1_score, log_loss, roc_auc_score, accuracy_score\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    " \n",
    "def load_variavle(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r\n",
    "\n",
    "def static_fe(data1,data2,df,column,values,cc,c):\n",
    "    addn = df[[column,values]].copy()\n",
    "    addn = addn.groupby(column)[values].agg(cc).reset_index()\n",
    "    addn.columns = [column] + [c+values+'_'+i for i in cc]\n",
    "    data1 = data1.merge(addn,on=column,how='left')\n",
    "    data2 = data2.merge(addn,on=column,how='left')\n",
    "    return data1,data2\n",
    "\n",
    "def cons(x):\n",
    "    num_times = [(k, len(list(v))) for k, v in itertools.groupby(list(x))]\n",
    "    num_times = pd.DataFrame(num_times)\n",
    "    num_times = num_times[num_times[0] == 1][1]\n",
    "    return num_times.max()\n",
    "\n",
    "def cons_fe(data,df,column,values):\n",
    "    kk = df.groupby(column)[values].apply(cons)\n",
    "    kk = kk.fillna(0).astype('int32').reset_index()\n",
    "    kk.columns = [column,'cons_' + values]\n",
    "    data = data.merge(kk, on=column, how='left')\n",
    "    return data\n",
    "\n",
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "\n",
    "def auc(y,pred):\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "def f1(y,pred):\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    return f1_score(y, pred, average='macro')\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "#     y_hat[y_hat>0.45] = 1\n",
    "#     y_hat[y_hat<=0.45] = 0\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat, average='macro'), True\n",
    "def lgb_accuracy_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat)\n",
    "    return 'accuracy', accuracy_score(y_true, y_hat), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = load_variavle('../data/id_map.pkl')\n",
    "new_map = {v:k for k, v in id_map.items()}\n",
    "col = ['活塞工作时长', '发动机转速', '油泵转速', '泵送压力', '液压油温', '流量档位', '分配压力', '排量电流',\n",
    "       '低压开关', '高压开关', '搅拌超压信号', '正泵', '反泵', '设备类型', 'sample_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = load_variavle('../data/data_all.pkl')\n",
    "data_all['活塞工作时长'] = data_all['活塞工作时长'].replace(2098,1)\n",
    "\"\"\"0.628\"\"\"\n",
    "shebeileixing = {7: 573, 6: 44, 5: 78, 4: 63, 3: 9, 2: 4, 1: 252}\n",
    "data_all['设备类型'] = data_all['设备类型'].map(shebeileixing)\n",
    "data_all['液压油温'] = data_all['液压油温'] + 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_labels.csv')\n",
    "test_data = pd.read_csv('../data/submit_example.csv')\n",
    "train_data['sample_file_name'] = train_data['sample_file_name'].map(new_map)\n",
    "test_data['sample_file_name'] = test_data['sample_file_name'].map(new_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = data_all.groupby(['设备类型','sample_file_name']).size().reset_index().rename(columns={0:'length'})\n",
    "train_data = train_data.merge(kk, on=['sample_file_name'], how='left')\n",
    "test_data = test_data.merge(kk, on=['sample_file_name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agg_func = {\n",
    "        '发动机转速': ['median', 'max', 'min', 'std'],\n",
    "        '油泵转速': ['median', 'max', 'min', 'std'],\n",
    "        '活塞工作时长': ['median', 'max', 'min'],\n",
    "        '泵送压力': ['median', 'max', 'min', 'std'],\n",
    "        '液压油温': ['median', 'max', 'min', 'std',],\n",
    "        '流量档位': ['median', 'max', 'min', 'std','sum'],\n",
    "        '分配压力': ['median', 'max', 'min', 'std','sum'],\n",
    "        '排量电流': ['median', 'max', 'min', 'std','sum'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = get_new_columns('id',agg_func)\n",
    "df_group = data_all.groupby('sample_file_name').agg(agg_func)\n",
    "df_group.columns = new_columns\n",
    "df_group.reset_index(drop=False,inplace=True)\n",
    "train_data = train_data.merge(df_group, on='sample_file_name', how='left')\n",
    "test_data = test_data.merge(df_group, on='sample_file_name', how='left')\n",
    "del df_group;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [i for i in train_data.columns if i not in ['sample_file_name', 'label']]\n",
    "X_train = train_data[col]\n",
    "y_train = train_data['label'].astype(int)\n",
    "X_test = test_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "seed = 2021\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************Fold_0**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6908719\ttest: 0.6910319\tbest: 0.6910319 (0)\ttotal: 125ms\tremaining: 2m 18s\n",
      "200:\tlearn: 0.6241799\ttest: 0.6460216\tbest: 0.6460216 (200)\ttotal: 7.97s\tremaining: 36.1s\n",
      "400:\tlearn: 0.6014897\ttest: 0.6380389\tbest: 0.6380389 (400)\ttotal: 15.9s\tremaining: 28.2s\n",
      "600:\tlearn: 0.5834113\ttest: 0.6336288\tbest: 0.6336288 (600)\ttotal: 23.9s\tremaining: 20.3s\n",
      "800:\tlearn: 0.5656748\ttest: 0.6298729\tbest: 0.6298637 (797)\ttotal: 31.9s\tremaining: 12.3s\n",
      "1000:\tlearn: 0.5501331\ttest: 0.6265477\tbest: 0.6265477 (1000)\ttotal: 39.8s\tremaining: 4.38s\n",
      "1110:\tlearn: 0.5412543\ttest: 0.6242010\tbest: 0.6242010 (1110)\ttotal: 44.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6242009594\n",
      "bestIteration = 1110\n",
      "\n",
      " *****************macro_f1 =  0.6493846140832116\n",
      "**************************************************Fold_1**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6908835\ttest: 0.6909653\tbest: 0.6909653 (0)\ttotal: 39.2ms\tremaining: 43.5s\n",
      "200:\tlearn: 0.6254056\ttest: 0.6400339\tbest: 0.6400339 (200)\ttotal: 8.18s\tremaining: 37s\n",
      "400:\tlearn: 0.6026859\ttest: 0.6311272\tbest: 0.6311272 (400)\ttotal: 16s\tremaining: 28.3s\n",
      "600:\tlearn: 0.5835234\ttest: 0.6250644\tbest: 0.6250644 (600)\ttotal: 23.9s\tremaining: 20.3s\n",
      "800:\tlearn: 0.5662704\ttest: 0.6205636\tbest: 0.6205636 (800)\ttotal: 31.8s\tremaining: 12.3s\n",
      "1000:\tlearn: 0.5503903\ttest: 0.6164259\tbest: 0.6164259 (1000)\ttotal: 39.8s\tremaining: 4.37s\n",
      "1110:\tlearn: 0.5421846\ttest: 0.6145988\tbest: 0.6145988 (1110)\ttotal: 44.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6145987623\n",
      "bestIteration = 1110\n",
      "\n",
      " *****************macro_f1 =  0.662717480961247\n",
      "**************************************************Fold_2**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6909284\ttest: 0.6909205\tbest: 0.6909205 (0)\ttotal: 35.2ms\tremaining: 39.1s\n",
      "200:\tlearn: 0.6256526\ttest: 0.6403400\tbest: 0.6403400 (200)\ttotal: 7.95s\tremaining: 36s\n",
      "400:\tlearn: 0.6031455\ttest: 0.6323371\tbest: 0.6323371 (400)\ttotal: 15.7s\tremaining: 27.7s\n",
      "600:\tlearn: 0.5837347\ttest: 0.6267205\tbest: 0.6267197 (599)\ttotal: 23.8s\tremaining: 20.2s\n",
      "800:\tlearn: 0.5665004\ttest: 0.6223809\tbest: 0.6223785 (798)\ttotal: 31.4s\tremaining: 12.2s\n",
      "1000:\tlearn: 0.5508736\ttest: 0.6189849\tbest: 0.6189849 (1000)\ttotal: 39s\tremaining: 4.28s\n",
      "1110:\tlearn: 0.5425596\ttest: 0.6173364\tbest: 0.6173364 (1110)\ttotal: 43.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6173364044\n",
      "bestIteration = 1110\n",
      "\n",
      " *****************macro_f1 =  0.6634985945954237\n",
      "**************************************************Fold_3**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6909740\ttest: 0.6908437\tbest: 0.6908437 (0)\ttotal: 36.2ms\tremaining: 40.2s\n",
      "200:\tlearn: 0.6260275\ttest: 0.6377575\tbest: 0.6377575 (200)\ttotal: 7.73s\tremaining: 35s\n",
      "400:\tlearn: 0.6031200\ttest: 0.6292010\tbest: 0.6292010 (400)\ttotal: 15.2s\tremaining: 27s\n",
      "600:\tlearn: 0.5836867\ttest: 0.6230792\tbest: 0.6230746 (598)\ttotal: 22.8s\tremaining: 19.3s\n",
      "800:\tlearn: 0.5666210\ttest: 0.6191862\tbest: 0.6191862 (800)\ttotal: 30.3s\tremaining: 11.7s\n",
      "1000:\tlearn: 0.5507204\ttest: 0.6154405\tbest: 0.6154405 (1000)\ttotal: 37.8s\tremaining: 4.16s\n",
      "1110:\tlearn: 0.5428182\ttest: 0.6137257\tbest: 0.6137257 (1110)\ttotal: 42.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6137256942\n",
      "bestIteration = 1110\n",
      "\n",
      " *****************macro_f1 =  0.6667048756233589\n",
      "**************************************************Fold_4**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6909354\ttest: 0.6909434\tbest: 0.6909434 (0)\ttotal: 37.9ms\tremaining: 42s\n",
      "200:\tlearn: 0.6255820\ttest: 0.6395733\tbest: 0.6395733 (200)\ttotal: 8s\tremaining: 36.2s\n",
      "400:\tlearn: 0.6026029\ttest: 0.6316586\tbest: 0.6316586 (400)\ttotal: 16s\tremaining: 28.3s\n",
      "600:\tlearn: 0.5834257\ttest: 0.6259837\tbest: 0.6259837 (600)\ttotal: 23.9s\tremaining: 20.3s\n",
      "800:\tlearn: 0.5660606\ttest: 0.6213447\tbest: 0.6213379 (797)\ttotal: 31.9s\tremaining: 12.3s\n",
      "1000:\tlearn: 0.5500564\ttest: 0.6168945\tbest: 0.6168945 (1000)\ttotal: 39.8s\tremaining: 4.37s\n",
      "1110:\tlearn: 0.5417985\ttest: 0.6150635\tbest: 0.6150635 (1110)\ttotal: 44.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6150635034\n",
      "bestIteration = 1110\n",
      "\n",
      " *****************macro_f1 =  0.661893722454235\n",
      " *****************mean_macro_f1 =  0.6608398575434953\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_pred_te_all = 0\n",
    "cat_macro_f1_mean = 0\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "\n",
    "    print( '*'*50+'Fold_'+str(i)+'*'*50)\n",
    "    y_tr, y_val = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "    X_tr, X_val= X_train.iloc[train_index,:].copy(), X_train.iloc[test_index,:].copy()\n",
    "    model = CatBoostClassifier(iterations=1111, #1111,1566\n",
    "                               depth = 7,#7\n",
    "                               loss_function='Logloss',#用于优化\n",
    "                               custom_loss='Accuracy',#F1,显示训练\n",
    "                               bagging_temperature=0.7,#1\n",
    "                               od_type='Iter',\n",
    "                               rsm = 0.67,#构建树时列采样0.67\n",
    "                               od_wait=100,\n",
    "                               l2_leaf_reg = 10,#11\n",
    "                               thread_count = 6,\n",
    "                               random_seed = 5,#5,9\n",
    "                               metric_period = 200,\n",
    "                              )\n",
    "    model.fit(X_tr, y_tr, eval_set=(X_val, y_val),\n",
    "              use_best_model=True)\n",
    "    pred = model.predict_proba(X_val)[:,1]\n",
    "    pred_te = model.predict_proba(X_test)[:,1]\n",
    "    print( \" *****************macro_f1 = \", f1_score(y_val, np.round(pred), average='macro'))\n",
    "    cat_pred_te_all = cat_pred_te_all + pred_te / K\n",
    "    cat_macro_f1_mean = f1_score(y_val, np.round(pred), average='macro') / K + cat_macro_f1_mean\n",
    "print( \" *****************mean_macro_f1 = \", cat_macro_f1_mean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    32304\n",
      "1.0    19946\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sub = test_data[['sample_file_name']].copy()\n",
    "sub['label'] = cat_pred_te_all\n",
    "sub['sample_file_name'] = sub['sample_file_name'].map(id_map)\n",
    "sub = sub.sort_values('label', ascending=False).reset_index(drop=True)\n",
    "print(sub['label'].round().value_counts())\n",
    "sub.loc[:23000,'label'] = 1\n",
    "sub.loc[23000:,'label'] = 0\n",
    "sub['label'] = sub['label'].astype(int)\n",
    "# 19946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../sub/cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
